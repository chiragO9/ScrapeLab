# ğŸ“š Books Scraper

A Python web scraper that extracts book information from [books.toscrape.com](https://books.toscrape.com/) including titles, prices, and star ratings.

## ğŸ¯ Features

- Extracts book titles from the website
- Retrieves pricing information for each book
- Collects star ratings (One to Five stars)
- Displays total count of books found
- Clean formatted output with f-strings

## ğŸ› ï¸ Technologies Used

- **Python 3.x**
- **BeautifulSoup4** - HTML parsing and web scraping
- **Requests** - HTTP library for making web requests
- **lxml** - XML and HTML parser

## ğŸ“‹ Prerequisites

Make sure you have Python installed on your system. You can check by running:
```bash
python --version
```

## ğŸš€ Installation

1. Clone this repository:
```bash
git clone https://github.com/YOUR_USERNAME/ScrapeLab.git
cd ScrapeLab
```

2. Install required dependencies:
```bash
pip install beautifulsoup4
pip install lxml
pip install requests
```

Or install from requirements.txt:
```bash
pip install -r requirements.txt
```

## ğŸ’» Usage

Run the scraper:
```bash
python books_scraper.py
```

## ğŸ“Š Sample Output
```
Total Books Found: 20

======================================================================
1. Title: A Light in the Attic
   Price: Â£51.77
   Rating: Three stars
----------------------------------------------------------------------
2. Title: Tipping the Velvet
   Price: Â£53.74
   Rating: One stars
----------------------------------------------------------------------
3. Title: Soumission
   Price: Â£50.10
   Rating: One stars
----------------------------------------------------------------------
...
```

## ğŸ“ Project Structure
```
ScrapeLab/
â”‚
â”œâ”€â”€ books_scraper.py      # Main scraper script
â”œâ”€â”€ requirements.txt      # Python dependencies
â”œâ”€â”€ README.md            # Project documentation
â””â”€â”€ .gitignore           # Git ignore file
```

## ğŸ” Code Explanation

### Main Components:

**1. Fetching the webpage:**
```python
html_text = requests.get('https://books.toscrape.com/').text
soup = BeautifulSoup(html_text, 'lxml')
```

**2. Finding all books:**
```python
books = soup.find_all('li', class_="col-xs-6 col-sm-4 col-md-3 col-lg-3")
```

**3. Extracting information:**
```python
book_title = book.find('h3').a['title']
price = book.find('p', class_='price_color').text
rating = book.find('p', class_='star-rating')['class'][1]
```

## ğŸ§  What I Learned

- How to make HTTP requests using the Requests library
- Parsing HTML content with BeautifulSoup
- Navigating the DOM to locate specific elements
- Extracting text content vs HTML attributes
- Understanding CSS class selectors
- Using f-strings for formatted output
- Working with lists and loops in Python

## ğŸ”§ Key Concepts

### HTML Attribute Access
```python
# Accessing attributes using bracket notation
element['title']    # Gets the title attribute
element['class']    # Gets class as a list
element['href']     # Gets the href attribute
```

### Star Rating Extraction
```python
# The class attribute returns a list: ['star-rating', 'Three']
rating = book.find('p', class_='star-rating')['class'][1]
# [0] = 'star-rating' (not useful)
# [1] = 'Three' (the actual rating)
```

## ğŸ“ Requirements

Create a `requirements.txt` file with:
```
beautifulsoup4==4.12.2
lxml==4.9.3
requests==2.31.0
```

## âš ï¸ Important Notes

- This project is for **educational purposes only**
- Always respect the website's `robots.txt` and terms of service
- The website [books.toscrape.com](https://books.toscrape.com/) is specifically designed for web scraping practice
- Be mindful of request frequency to avoid overloading servers

## ğŸš§ Future Enhancements

- [ ] Add data export to CSV format
- [ ] Implement multi-page scraping (pagination)
- [ ] Add error handling for network issues
- [ ] Filter books by price range
- [ ] Sort books by rating
- [ ] Create data visualizations

## ğŸ¤ Contributing

This is a personal learning project, but suggestions and feedback are welcome!

## ğŸ“„ License

This project is open source and available for educational purposes.

## ğŸ“§ Contact

Feel free to reach out if you have questions or suggestions!

---

â­ If you found this helpful, please give it a star!

**Happy Scraping!** ğŸš€
```

---

## Also Create These Files:

### **requirements.txt:**
```
beautifulsoup4==4.12.2
lxml==4.9.3
requests==2.31.0
```

### **.gitignore:**
```
# Python
__pycache__/
*.py[cod]
*$py.class
*.pyc
*.pyo
*.pyd
.Python
env/
venv/
ENV/

# IDE
.vscode/
.idea/
*.swp
*.swo

# OS
.DS_Store
Thumbs.db

# Project specific
*.csv
*.json
output/
